{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo VAE para reconstrução e mistura de imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grandes partes copiadas [deste modelo](https://github.com/Data-Science-kosta/Variational-Autoencoder-for-Face-Generation/blob/master/VAE_celebFaces.ipynb),\n",
    "com alguns bugfixes que não funcionam em versões mais novas do tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose\n",
    "from keras.layers import LeakyReLU, Flatten, Dropout, Dense\n",
    "from keras.layers import Lambda, BatchNormalization, Reshape, Activation\n",
    "from keras.models import load_model, Model\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, CSVLogger\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K\n",
    "from PIL import Image\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "\n",
    "disable_eager_execution()\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# import Adam\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "# tf seed\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../models/50epochs\"\n",
    "show_plots = False\n",
    "# train the VAE with fit_generator\n",
    "learning_rate = 5e-4\n",
    "learning_rate_decay = 0.999\n",
    "R_LOSS_FACTOR = 10000\n",
    "INPUT_DIMS = (128, 128, 3)\n",
    "EPOCHS = 50\n",
    "INITIAL_EPOCH = 0\n",
    "BATCH_SIZE = 30\n",
    "LATENT_SPACE_SIZE = 100\n",
    "patience_steps = 5\n",
    "OPTIMIZER = Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./keras_vae\"\n",
    "FINAL_DATA_DIR = f\"{DATA_DIR}/inside\"\n",
    "IMGS_DIR = f\"{FINAL_DATA_DIR}/renamed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_disk(txt_path, values):\n",
    "    if os.path.isfile(txt_path):\n",
    "        os.remove(txt_path)\n",
    "    with open(txt_path, \"wb\") as fp:\n",
    "        pickle.dump(values, fp)\n",
    "    return\n",
    "\n",
    "\n",
    "def load_from_disk(txt_path):\n",
    "    with open(txt_path, \"rb\") as f:\n",
    "        values = pickle.load(f)\n",
    "    return values\n",
    "\n",
    "\n",
    "class ReconstructFaceCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, save_path, VAE):\n",
    "        self.save_path = save_path\n",
    "        self.VAE = VAE\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        example_ind = 0\n",
    "        # image_path = os.path.join(\"img_align_celeba/img_align_celeba\",str(example_ind).zfill(6)+\".jpg\")\n",
    "        # ../../data/dogs/vae\n",
    "        image_path = os.path.join(\n",
    "            FINAL_DATA_DIR, \"train_renamed\", str(example_ind).zfill(6) + \".jpg\"\n",
    "        )\n",
    "        pil_image = Image.open(image_path)\n",
    "        pil_image = pil_image.resize(\n",
    "            (INPUT_DIMS[0], INPUT_DIMS[1]), Image.Resampling.LANCZOS\n",
    "        )\n",
    "        image = np.array(pil_image) / 255.0\n",
    "\n",
    "        latent_space = self.VAE.encoder.predict(np.expand_dims(image, 0))\n",
    "        reconstructed_image = self.VAE.decoder.predict(latent_space)\n",
    "\n",
    "        if show_plots:\n",
    "            plt.figure()\n",
    "            plt.imshow(reconstructed_image.squeeze())\n",
    "            plt.show()\n",
    "\n",
    "        plt.imsave(\n",
    "            os.path.join(self.save_path, \"reconstructed_{}.jpg\".format(epoch)),\n",
    "            reconstructed_image.squeeze(),\n",
    "        )\n",
    "\n",
    "\n",
    "class VariationalAutoencoder(object):\n",
    "    def __init__(self):\n",
    "        self.nothing = 10\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dims,\n",
    "        latent_space_size,\n",
    "        encoder_filters,\n",
    "        encoder_kernel_size,\n",
    "        encoder_strides,\n",
    "        encoder_padding,\n",
    "        decoder_filters,\n",
    "        decoder_kernel_size,\n",
    "        decoder_strides,\n",
    "        decoder_padding,\n",
    "    ):\n",
    "        self.input_dims = input_dims\n",
    "        self.latent_space_size = latent_space_size\n",
    "        self.encoder_filters = encoder_filters\n",
    "        self.encoder_kernel_size = encoder_kernel_size\n",
    "        self.encoder_strides = encoder_strides\n",
    "        self.encoder_padding = encoder_padding\n",
    "        self.decoder_filters = decoder_filters\n",
    "        self.decoder_kernel_size = decoder_kernel_size\n",
    "        self.decoder_strides = decoder_strides\n",
    "        self.decoder_padding = decoder_padding\n",
    "        self._create_model()\n",
    "\n",
    "    def _create_model(self):\n",
    "        self.images = Input(shape=self.input_dims, name=\"images\")\n",
    "        # create encoder as separate model\n",
    "        encoder_shape_before_flattening = self._create_encoder()\n",
    "        # create decoder as separate model\n",
    "        self.decoder_input = Input(\n",
    "            shape=(self.latent_space_size,), name=\"decoder_input\"\n",
    "        )\n",
    "        self._create_decoder(encoder_shape_before_flattening)\n",
    "        # create unique model\n",
    "        self.model = Model(\n",
    "            inputs=self.images, outputs=self.decoder(self.encoder_output)\n",
    "        )\n",
    "\n",
    "    def _create_encoder(self):\n",
    "        # create convolutional layers for encoder\n",
    "        X = self.images\n",
    "        for i in range(len(self.encoder_filters)):\n",
    "            X = self._create_conv_layer(\n",
    "                X,\n",
    "                \"Conv2D\",\n",
    "                self.encoder_filters[i],\n",
    "                self.encoder_kernel_size[i],\n",
    "                self.encoder_strides[i],\n",
    "                self.encoder_padding[i],\n",
    "                \"encoder_conv\" + str(i),\n",
    "            )\n",
    "        # keep track of tensor shape before flattening (we will need this to build decoder)\n",
    "        encoder_shape_before_flattening = K.int_shape(X)[1:]\n",
    "        # flatten the tensor\n",
    "        X = Flatten()(X)\n",
    "        # create dense layers for mu and sigma\n",
    "        self.encoder_mu = Dense(units=self.latent_space_size, name=\"encoder_mu\")(X)\n",
    "        self.encoder_log_var = Dense(\n",
    "            units=self.latent_space_size, name=\"encoder_log_var\"\n",
    "        )(X)\n",
    "        self.encoder_parameters = Model(\n",
    "            self.images, (self.encoder_mu, self.encoder_log_var)\n",
    "        )\n",
    "        # create encoder output by sampling from normal distribution\n",
    "        self.encoder_output = Lambda(self.sample_latent_space, name=\"encoder_output\")(\n",
    "            [self.encoder_mu, self.encoder_log_var]\n",
    "        )\n",
    "        self.encoder = Model(inputs=self.images, outputs=self.encoder_output)\n",
    "        return encoder_shape_before_flattening\n",
    "\n",
    "    def _create_decoder(self, encoder_shape_before_flattening):\n",
    "        X = Dense(np.prod(encoder_shape_before_flattening))(self.decoder_input)\n",
    "        X = Reshape(encoder_shape_before_flattening)(X)\n",
    "        # create convolutional layers for decoder\n",
    "        for i in range(len(self.decoder_filters)):\n",
    "            is_not_last_layer = i < len(self.decoder_filters) - 1\n",
    "            X = self._create_conv_layer(\n",
    "                X,\n",
    "                \"Conv2DTranspose\",\n",
    "                self.decoder_filters[i],\n",
    "                self.decoder_kernel_size[i],\n",
    "                self.decoder_strides[i],\n",
    "                self.decoder_padding[i],\n",
    "                \"decoder_conv\" + str(i),\n",
    "                batch_norm=is_not_last_layer,\n",
    "                dropout=is_not_last_layer,\n",
    "                activation=is_not_last_layer,\n",
    "            )\n",
    "        # output values should be between 0 and 1\n",
    "        self.decoder_output = Activation(\"sigmoid\")(X)\n",
    "        self.decoder = Model(inputs=self.decoder_input, outputs=self.decoder_output)\n",
    "\n",
    "    def _create_conv_layer(\n",
    "        self,\n",
    "        input,\n",
    "        convolution_type,\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        strides,\n",
    "        padding,\n",
    "        name,\n",
    "        batch_norm=True,\n",
    "        dropout=True,\n",
    "        activation=True,\n",
    "    ):\n",
    "        convolution = getattr(\n",
    "            keras.layers, convolution_type\n",
    "        )  # sets Conv2D or Conv2DTranspaose\n",
    "        conv_layer = convolution(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            name=name,\n",
    "        )\n",
    "        X = conv_layer(input)\n",
    "        if batch_norm:\n",
    "            X = BatchNormalization()(X)\n",
    "        if activation:\n",
    "            X = LeakyReLU()(X)\n",
    "        if dropout:\n",
    "            X = Dropout(rate=0.25)(X)\n",
    "        return X\n",
    "\n",
    "    def sample_latent_space(self, mu_and_log_var):\n",
    "        mu, log_var = mu_and_log_var\n",
    "        normal_samples = K.random_normal(shape=K.shape(mu), mean=0.0, stddev=1.0)\n",
    "        return mu + K.exp(log_var / 2) * normal_samples\n",
    "\n",
    "    def compile(self, optimizer, r_loss_factor):\n",
    "        self.model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=self.penalized_loss(r_loss_factor),\n",
    "            metrics=[self.penalized_loss(r_loss_factor)],\n",
    "        )\n",
    "\n",
    "    def penalized_loss(self, r_loss_factor):\n",
    "        def loss(y, y_hat):\n",
    "            # reconstruction_loss\n",
    "            r_loss = K.mean(\n",
    "                K.square(y - y_hat), axis=[1, 2, 3]\n",
    "            )  # dont do mean on batch axis\n",
    "            # KL loss\n",
    "            kl_loss = -0.5 * K.sum(\n",
    "                1\n",
    "                + self.encoder_log_var\n",
    "                - K.square(self.encoder_mu)\n",
    "                - K.exp(self.encoder_log_var),\n",
    "                axis=1,\n",
    "            )\n",
    "            return r_loss * r_loss_factor + kl_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        save_path,\n",
    "        data_flow,\n",
    "        epochs,\n",
    "        steps_per_epoch,\n",
    "        initial_epoch=0,\n",
    "        lr_decay=1,\n",
    "        learning_rate=0.0005,\n",
    "    ):\n",
    "        learning_rate_schedule = self.step_decay_schedule(\n",
    "            initial_lr=learning_rate, decay_factor=lr_decay, step_size=1\n",
    "        )\n",
    "        # history_logger = CSVLogger(os.path.join(save_path, \"history.csv\"), append=True)\n",
    "        checkpoint_model = ModelCheckpoint(\n",
    "            os.path.join(save_path, \"model.h5\"), verbose=1\n",
    "        )\n",
    "        checkpoint_weights = ModelCheckpoint(\n",
    "            os.path.join(save_path, \"weights.h5\"), save_weights_only=True, verbose=1\n",
    "        )\n",
    "        checkpoint_encoder = ModelCheckpoint(\n",
    "            os.path.join(save_path, \"encoder.h5\"), verbose=1\n",
    "        )\n",
    "        checkpoint_encoder.set_model(self.encoder)\n",
    "        checkpoint_decoder = ModelCheckpoint(\n",
    "            os.path.join(save_path, \"decoder.h5\"), verbose=1\n",
    "        )\n",
    "        checkpoint_decoder.set_model(self.decoder)\n",
    "        reconstruct_callback = ReconstructFaceCallback(\n",
    "            os.path.join(save_path, \"plots\"), self\n",
    "        )\n",
    "\n",
    "        # history = self.model.fit_generator(\n",
    "        #     data_flow,\n",
    "        #     shuffle = True,\n",
    "        #     epochs = epochs,\n",
    "        #     initial_epoch = initial_epoch,\n",
    "        #     steps_per_epoch = steps_per_epoch,\n",
    "        #     callbacks = [learning_rate_schedule,\n",
    "        #                  history_logger,\n",
    "        #                  checkpoint_weights,\n",
    "        #                  checkpoint_model,\n",
    "        #                  checkpoint_encoder,\n",
    "        #                  checkpoint_decoder,\n",
    "        #                  reconstruct_callback\n",
    "        #                  ],\n",
    "        #     verbose=1\n",
    "        #     )\n",
    "\n",
    "        history = self.model.fit(\n",
    "            x=data_flow,\n",
    "            shuffle=True,\n",
    "            epochs=epochs,\n",
    "            initial_epoch=initial_epoch,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            callbacks=[\n",
    "                learning_rate_schedule,\n",
    "                # history_logger,\n",
    "                checkpoint_weights,\n",
    "                checkpoint_model,\n",
    "                checkpoint_encoder,\n",
    "                checkpoint_decoder,\n",
    "                reconstruct_callback,\n",
    "                early_stopping_callback,\n",
    "            ],\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        return history\n",
    "\n",
    "    def step_decay_schedule(self, initial_lr, decay_factor, step_size):\n",
    "        def schedule(epoch):\n",
    "            return initial_lr * (decay_factor ** np.floor(epoch / step_size))\n",
    "\n",
    "        return LearningRateScheduler(schedule)\n",
    "\n",
    "    def load_trained_model(self, load_path, r_loss_factor):\n",
    "        self.model = load_model(\n",
    "            os.path.join(load_path, \"model.h5\"),\n",
    "            custom_objects={\n",
    "                \"loss\": self.penalized_loss(r_loss_factor),\n",
    "                \"sample_latent_space\": self.sample_latent_space,\n",
    "            },\n",
    "        )\n",
    "        self.encoder = load_model(\n",
    "            os.path.join(load_path, \"encoder.h5\"),\n",
    "            custom_objects={\n",
    "                \"loss\": self.penalized_loss(r_loss_factor),\n",
    "                \"sample_latent_space\": self.sample_latent_space,\n",
    "            },\n",
    "        )\n",
    "        self.decoder = load_model(\n",
    "            os.path.join(load_path, \"decoder.h5\"),\n",
    "            custom_objects={\n",
    "                \"loss\": self.penalized_loss(r_loss_factor),\n",
    "                \"sample_latent_space\": self.sample_latent_space,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def load_trained_weights(self, load_path):\n",
    "        self.model.load_weights(os.path.join(load_path, \"weights.h5\"))\n",
    "\n",
    "    def plot_model(self, plots_path):\n",
    "        plots_path = os.path.join(plots_path, \"plots\")\n",
    "        os.makedirs(plots_path, exist_ok=True)\n",
    "        plot_model(\n",
    "            self.model,\n",
    "            to_file=os.path.join(plots_path, \"model.png\"),\n",
    "            show_shapes=True,\n",
    "            show_layer_names=True,\n",
    "        )\n",
    "        plot_model(\n",
    "            self.encoder,\n",
    "            to_file=os.path.join(plots_path, \"encoder.png\"),\n",
    "            show_shapes=True,\n",
    "            show_layer_names=True,\n",
    "        )\n",
    "        plot_model(\n",
    "            self.decoder,\n",
    "            to_file=os.path.join(plots_path, \"decoder.png\"),\n",
    "            show_shapes=True,\n",
    "            show_layer_names=True,\n",
    "        )\n",
    "        print(\"Models are ploted in {}\".format(plots_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instancia do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE = VariationalAutoencoder(\n",
    "    input_dims=INPUT_DIMS,\n",
    "    latent_space_size=LATENT_SPACE_SIZE,\n",
    "    encoder_filters=[32, 64, 64, 64],\n",
    "    encoder_kernel_size=[3, 3, 3, 3],\n",
    "    encoder_strides=[2, 2, 2, 2],\n",
    "    encoder_padding=[\"same\", \"same\", \"same\", \"same\"],\n",
    "    decoder_filters=[64, 64, 32, 3],\n",
    "    decoder_kernel_size=[3, 3, 3, 3],\n",
    "    decoder_strides=[2, 2, 2, 2],\n",
    "    decoder_padding=[\"same\", \"same\", \"same\", \"same\"],\n",
    ")\n",
    "\n",
    "print(\"Encoder and decoder model summary:\")\n",
    "VAE.encoder.summary()\n",
    "VAE.decoder.summary()\n",
    "\n",
    "VAE.compile(OPTIMIZER, R_LOSS_FACTOR)\n",
    "# VAE.plot_model(\"google_drive/My Drive/Colab Notebooks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = os.path.join(os.getcwd(), \"./data/archive/\")\n",
    "DATA_DOG_PATH = FINAL_DATA_DIR\n",
    "file_names = []\n",
    "\n",
    "for file_name in os.listdir(os.path.join(DATA_DOG_PATH, \"train_renamed\")):\n",
    "    file_names.append(file_name)\n",
    "DATASET_SIZE = len(file_names)\n",
    "# create image generator and data flow\n",
    "data_generator = ImageDataGenerator(rescale=1.0 / 255)\n",
    "data_flow = data_generator.flow_from_directory(\n",
    "    DATA_DOG_PATH,\n",
    "    target_size=INPUT_DIMS[:2],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode=\"input\",\n",
    "    subset=\"training\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create if dont exist\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    os.makedirs(os.path.join(save_path, \"plots\"))\n",
    "\n",
    "history = VAE.train(\n",
    "    save_path=save_path,\n",
    "    data_flow=data_flow,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=int(DATASET_SIZE / BATCH_SIZE),\n",
    "    initial_epoch=INITIAL_EPOCH,\n",
    "    learning_rate=learning_rate,\n",
    "    lr_decay=learning_rate_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O checkpoint já salva automaticamente os modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(folder_path, example_ind, INPUT_DIMS=(128, 128, 3)):\n",
    "    image_path = os.path.join(folder_path, str(example_ind).zfill(6) + \".jpg\")\n",
    "    pil_image = Image.open(image_path)\n",
    "    pil_image = pil_image.resize(\n",
    "        (INPUT_DIMS[0], INPUT_DIMS[1]), Image.Resampling.LANCZOS\n",
    "    )\n",
    "    image = np.array(pil_image) / 255.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplo para reconstrução\n",
    "example_ind = 500\n",
    "image = loadImage(IMGS_DIR, example_ind)\n",
    "\n",
    "latent_space = VAE.encoder.predict(np.expand_dims(image, 0))\n",
    "reconstructed_image = VAE.decoder.predict(latent_space)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.figure()\n",
    "plt.imshow(reconstructed_image.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistura dos dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphBetweenImages(example_ind1, example_ind2, VAE, images_path, num_of_morphs):\n",
    "    # load images\n",
    "    img1 = loadImage(images_path, example_ind1)\n",
    "    img2 = loadImage(images_path, example_ind2)\n",
    "    # define alpha\n",
    "    alpha = np.linspace(0, 1, num_of_morphs)\n",
    "    # get latent spaces\n",
    "    z1 = VAE.encoder.predict(np.expand_dims(img1, 0))\n",
    "    z2 = VAE.encoder.predict(np.expand_dims(img2, 0))\n",
    "    # morph and plot\n",
    "    fig = plt.figure(figsize=(30, 30))\n",
    "    ax = fig.add_subplot(1, num_of_morphs + 2, 1)\n",
    "    ax.imshow(img1)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(loc=\"center\", label=\"original image 1\", fontsize=10)\n",
    "    for i in range(num_of_morphs):\n",
    "        z = z1 * (1 - alpha[i]) + z2 * alpha[i]\n",
    "        new_img = VAE.decoder.predict(z)\n",
    "        ax = fig.add_subplot(1, num_of_morphs + 2, i + 2)\n",
    "        ax.imshow(new_img.squeeze())\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(loc=\"center\", label=\"alpha={:.2f}\".format(alpha[i]))\n",
    "    ax = fig.add_subplot(1, num_of_morphs + 2, num_of_morphs + 2)\n",
    "    ax.imshow(img2)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(loc=\"center\", label=\"original image 2\", fontsize=10)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_ind1 = 100\n",
    "example_ind2 = 3000\n",
    "num_of_morphs = 10\n",
    "\n",
    "morphBetweenImages(example_ind1, example_ind2, VAE, IMGS_DIR, num_of_morphs)  # VAE,"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
